{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# !pip install transformers --user\n",
    "# !pip install pandas --user\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def empty_cache():\n",
    "  gc.collect()\n",
    "  torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BartForConditionalGeneration, BartTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install wandb\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = 'distilbart-sum400-summarized'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe, tokenizer, source_len, summ_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.source_len = source_len\n",
    "        self.summ_len = summ_len\n",
    "        self.ementa = self.data.ementa\n",
    "        self.inteiro_teor = self.data.inteiro_teor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ementa)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        inteiro_teor = str(self.inteiro_teor[index])\n",
    "        inteiro_teor = ' '.join(inteiro_teor.split())\n",
    "\n",
    "        ementa = str(self.ementa[index])\n",
    "        ementa = ' '.join(ementa.split())\n",
    "\n",
    "        source = self.tokenizer.batch_encode_plus([inteiro_teor], max_length=self.source_len, pad_to_max_length=True,return_tensors='pt', truncation=True)\n",
    "        target = self.tokenizer.batch_encode_plus([ementa], max_length=self.summ_len, pad_to_max_length=True,return_tensors='pt', truncation=True)\n",
    "\n",
    "        source_ids = source['input_ids'].squeeze()\n",
    "        source_mask = source['attention_mask'].squeeze()\n",
    "        target_ids = target['input_ids'].squeeze()\n",
    "        target_mask = target['attention_mask'].squeeze()\n",
    "\n",
    "        return {\n",
    "            'source_ids': source_ids.to(dtype=torch.long), \n",
    "            'source_mask': source_mask.to(dtype=torch.long), \n",
    "            'target_ids': target_ids.to(dtype=torch.long),\n",
    "            'target_ids_y': target_ids.to(dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, tokenizer, model, device, loader, optimizer):\n",
    "    model.train()\n",
    "    for _,data in enumerate(loader, 0):\n",
    "        y = data['target_ids'].to(device, dtype = torch.long)\n",
    "        y_ids = y[:, :-1].contiguous()\n",
    "        lm_labels = y[:, 1:].clone().detach()\n",
    "        lm_labels[y[:, 1:] == tokenizer.pad_token_id] = -100\n",
    "        ids = data['source_ids'].to(device, dtype = torch.long)\n",
    "        mask = data['source_mask'].to(device, dtype = torch.long)\n",
    "\n",
    "        outputs = model(input_ids=ids, attention_mask=mask, decoder_input_ids=y_ids, lm_labels=lm_labels)\n",
    "        loss = outputs[0]\n",
    "        \n",
    "        empty_cache()\n",
    "        \n",
    "        if _ % 10 == 0:\n",
    "            wandb.log({\"Loss do treinamento\": loss.item()})\n",
    "\n",
    "        if _ % 500 == 0:\n",
    "            print(f'Época: {epoch}, Loss:  {loss.item()}')\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['WANDB_API_KEY'] = 'key'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_wandb(project_name):\n",
    "    wandb.init(project=project_name) \n",
    "    config = wandb.config\n",
    "    config.TRAIN_BATCH_SIZE = 1\n",
    "    config.VALID_BATCH_SIZE = 1\n",
    "    config.TRAIN_EPOCHS = 16\n",
    "    config.VAL_EPOCHS = 1 \n",
    "    config.LEARNING_RATE = 1e-4\n",
    "    config.MAX_LEN = 1024\n",
    "    config.SUMMARY_LEN = 400\n",
    "\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_training_pipeline(config):\n",
    "    print('Iniciando pipeline...\\n\\n')\n",
    "\n",
    "    model_name = 'sshleifer/bart-tiny-random'\n",
    "    tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    empty_cache()\n",
    "    \n",
    "    train_dataset = pd.read_csv('../../data/train/translated-train-400-2500-summarized-new.csv', encoding='utf-8', error_bad_lines=False, engine=\"python\")\n",
    "    train_dataset = train_dataset[['ementa','inteiro_teor']]\n",
    "    print('Exemplo de textos:')\n",
    "    print(train_dataset.head(), '\\n\\n')\n",
    "    \n",
    "    val_dataset = pd.read_csv('../../data/train/translated-validate-400-2500-summarized-new.csv', encoding='utf-8', error_bad_lines=False, engine=\"python\")\n",
    "    val_dataset = val_dataset[['ementa','inteiro_teor']]\n",
    "\n",
    "    print(f'Dataset de treino: {train_dataset.shape}')\n",
    "    print(f'Dataset de teste: {val_dataset.shape}')\n",
    "\n",
    "    val_set = CustomDataset(val_dataset, tokenizer, config.MAX_LEN, config.SUMMARY_LEN)\n",
    "\n",
    "    train_params = {'batch_size': config.TRAIN_BATCH_SIZE, 'shuffle': True, 'num_workers': 0}\n",
    "    val_params = {'batch_size': config.VALID_BATCH_SIZE, 'shuffle': False, 'num_workers': 0}\n",
    "\n",
    "    training_loader = DataLoader(training_set, **train_params)\n",
    "    val_loader = DataLoader(val_set, **val_params)\n",
    "    \n",
    "    print('Instanciando modelo...')\n",
    "    model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(params =  model.parameters(), lr=config.LEARNING_RATE)\n",
    "\n",
    "    empty_cache()\n",
    "\n",
    "    wandb.watch(model, log=\"all\")\n",
    "    \n",
    "    print('Inicializando Fine-Tuning utilizando o dataset de acórdãos...')\n",
    "\n",
    "    for epoch in range(config.TRAIN_EPOCHS):\n",
    "        train(epoch, tokenizer, model, device, training_loader, optimizer)\n",
    "\n",
    "        empty_cache()\n",
    "\n",
    "    print('Treinamento concluído!\\n\\n')\n",
    "\n",
    "    return tokenizer, model, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:wandb.jupyter:Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mthiagocmoreira\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.4 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201006_213546-2pqv722y\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdaily-planet-8\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/thiagocmoreira/distilbart-sum400-summarized\" target=\"_blank\">https://app.wandb.ai/thiagocmoreira/distilbart-sum400-summarized</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/thiagocmoreira/distilbart-sum400-summarized/runs/2pqv722y\" target=\"_blank\">https://app.wandb.ai/thiagocmoreira/distilbart-sum400-summarized/runs/2pqv722y</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "config = init_wandb(project_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando pipeline...\n",
      "\n",
      "\n",
      "Exemplo de textos:\n",
      "                                              ementa  \\\n",
      "0  interlocutory appeal. Work accident. partial r...   \n",
      "1  interlocutory appeal. innominate precautionary...   \n",
      "2  declaration embargoes. addictions. inexistence...   \n",
      "3  interlocutory appeal. timing. jurisprudential ...   \n",
      "4  interlocutory appeal. illicit outsourcing. Pre...   \n",
      "\n",
      "                                        inteiro_teor  \n",
      "0  judgment 6th class acv / rp This document of i...  \n",
      "1  the c o rd (1st class class) gmwoc / db seen, ...  \n",
      "2  judgment 5th class emp / igr visa, reported an...  \n",
      "3  the c o rd (6th class) gmacc / sc / jr / pv vi...  \n",
      "4  judgment 6th class acv / acc visa, report and ...   \n",
      "\n",
      "\n",
      "Dataset de treino: (10791, 2)\n",
      "Dataset de teste: (2698, 2)\n",
      "Instanciando modelo...\n",
      "Inicializando Fine-Tuning utilizando o dataset de acórdãos...\n",
      "Época: 0, Loss:  10.833200454711914\n",
      "Época: 0, Loss:  8.484423637390137\n",
      "Época: 0, Loss:  6.410473346710205\n",
      "Época: 0, Loss:  6.069296836853027\n",
      "Época: 0, Loss:  5.732072353363037\n",
      "Época: 0, Loss:  4.983277320861816\n",
      "Época: 0, Loss:  5.2781662940979\n",
      "Época: 0, Loss:  4.816668510437012\n",
      "Época: 0, Loss:  5.460480690002441\n",
      "Época: 0, Loss:  5.275938510894775\n",
      "Época: 0, Loss:  6.249656677246094\n",
      "Época: 0, Loss:  4.4661102294921875\n",
      "Época: 0, Loss:  5.087742328643799\n",
      "Época: 0, Loss:  5.031840801239014\n",
      "Época: 0, Loss:  3.940093517303467\n",
      "Época: 0, Loss:  3.668879747390747\n",
      "Época: 0, Loss:  5.143486976623535\n",
      "Época: 0, Loss:  4.700157165527344\n",
      "Época: 0, Loss:  3.211215019226074\n",
      "Época: 0, Loss:  4.274655818939209\n",
      "Época: 0, Loss:  4.640224456787109\n",
      "Época: 0, Loss:  2.99068546295166\n",
      "Época: 1, Loss:  2.074418544769287\n",
      "Época: 1, Loss:  2.5186562538146973\n",
      "Época: 1, Loss:  3.0072336196899414\n",
      "Época: 1, Loss:  2.531036376953125\n",
      "Época: 1, Loss:  3.4686200618743896\n",
      "Época: 1, Loss:  2.0785341262817383\n",
      "Época: 1, Loss:  3.72969388961792\n",
      "Época: 1, Loss:  2.6255178451538086\n",
      "Época: 1, Loss:  3.729001045227051\n",
      "Época: 1, Loss:  2.856435775756836\n",
      "Época: 1, Loss:  1.375096082687378\n",
      "Época: 1, Loss:  3.4034230709075928\n",
      "Época: 1, Loss:  3.0385982990264893\n",
      "Época: 1, Loss:  3.5964066982269287\n",
      "Época: 1, Loss:  2.216536045074463\n",
      "Época: 1, Loss:  2.926335334777832\n",
      "Época: 1, Loss:  3.8995590209960938\n",
      "Época: 1, Loss:  3.253699541091919\n",
      "Época: 1, Loss:  2.986891269683838\n",
      "Época: 1, Loss:  2.988048553466797\n",
      "Época: 1, Loss:  1.1818207502365112\n",
      "Época: 1, Loss:  1.4937775135040283\n",
      "Época: 2, Loss:  3.8591134548187256\n",
      "Época: 2, Loss:  2.5873899459838867\n",
      "Época: 2, Loss:  2.9683234691619873\n",
      "Época: 2, Loss:  3.3331241607666016\n",
      "Época: 2, Loss:  2.9298341274261475\n",
      "Época: 2, Loss:  1.844691514968872\n",
      "Época: 2, Loss:  2.631159782409668\n",
      "Época: 2, Loss:  2.6466915607452393\n",
      "Época: 2, Loss:  3.0511014461517334\n",
      "Época: 2, Loss:  1.7302671670913696\n",
      "Época: 2, Loss:  3.344146251678467\n",
      "Época: 2, Loss:  3.123587131500244\n",
      "Época: 2, Loss:  3.7666280269622803\n",
      "Época: 2, Loss:  1.351703405380249\n",
      "Época: 2, Loss:  3.035503625869751\n",
      "Época: 2, Loss:  0.9424731731414795\n",
      "Época: 2, Loss:  3.775899887084961\n",
      "Época: 2, Loss:  2.4773359298706055\n",
      "Época: 2, Loss:  2.221954584121704\n",
      "Época: 2, Loss:  4.3138909339904785\n",
      "Época: 2, Loss:  0.8133527040481567\n",
      "Época: 2, Loss:  2.079813241958618\n",
      "Época: 3, Loss:  3.139193296432495\n",
      "Época: 3, Loss:  0.8916566371917725\n",
      "Época: 3, Loss:  4.295820713043213\n",
      "Época: 3, Loss:  2.3489744663238525\n",
      "Época: 3, Loss:  1.8934885263442993\n",
      "Época: 3, Loss:  2.7486493587493896\n",
      "Época: 3, Loss:  0.7052375078201294\n",
      "Época: 3, Loss:  5.075742244720459\n",
      "Época: 3, Loss:  0.7527252435684204\n",
      "Época: 3, Loss:  2.507063150405884\n",
      "Época: 3, Loss:  2.8453609943389893\n",
      "Época: 3, Loss:  2.8429298400878906\n",
      "Época: 3, Loss:  2.1139376163482666\n",
      "Época: 3, Loss:  2.3839266300201416\n",
      "Época: 3, Loss:  2.775242567062378\n",
      "Época: 3, Loss:  1.6014344692230225\n",
      "Época: 3, Loss:  3.8252758979797363\n",
      "Época: 3, Loss:  3.608203649520874\n",
      "Época: 3, Loss:  3.3969202041625977\n",
      "Época: 3, Loss:  0.8466648459434509\n",
      "Época: 3, Loss:  3.2770328521728516\n",
      "Época: 3, Loss:  2.4168498516082764\n",
      "Época: 4, Loss:  2.5229740142822266\n",
      "Época: 4, Loss:  3.6417717933654785\n",
      "Época: 4, Loss:  4.018930912017822\n",
      "Época: 4, Loss:  2.2257778644561768\n",
      "Época: 4, Loss:  1.2920756340026855\n",
      "Época: 4, Loss:  0.7926343083381653\n",
      "Época: 4, Loss:  0.7013935446739197\n",
      "Época: 4, Loss:  2.1206750869750977\n",
      "Época: 4, Loss:  2.657021999359131\n",
      "Época: 4, Loss:  2.953838348388672\n",
      "Época: 4, Loss:  1.1685879230499268\n",
      "Época: 4, Loss:  3.934589147567749\n",
      "Época: 4, Loss:  2.685725212097168\n",
      "Época: 4, Loss:  0.7000393271446228\n",
      "Época: 4, Loss:  2.7072184085845947\n",
      "Época: 4, Loss:  2.053602695465088\n",
      "Época: 4, Loss:  2.8490140438079834\n",
      "Época: 4, Loss:  1.3705377578735352\n",
      "Época: 4, Loss:  1.6455060243606567\n",
      "Época: 4, Loss:  2.4181926250457764\n",
      "Época: 4, Loss:  2.9930248260498047\n",
      "Época: 4, Loss:  3.084324836730957\n",
      "Época: 5, Loss:  2.850877523422241\n",
      "Época: 5, Loss:  3.75083327293396\n",
      "Época: 5, Loss:  1.646193027496338\n",
      "Época: 5, Loss:  2.0579888820648193\n",
      "Época: 5, Loss:  2.58567214012146\n",
      "Época: 5, Loss:  2.6972551345825195\n",
      "Época: 5, Loss:  1.932558536529541\n",
      "Época: 5, Loss:  1.1438781023025513\n",
      "Época: 5, Loss:  2.559211254119873\n",
      "Época: 5, Loss:  3.88935923576355\n",
      "Época: 5, Loss:  3.112839937210083\n",
      "Época: 5, Loss:  1.6817028522491455\n",
      "Época: 5, Loss:  0.5631875991821289\n",
      "Época: 5, Loss:  1.752537488937378\n",
      "Época: 5, Loss:  3.799247980117798\n",
      "Época: 5, Loss:  3.369357109069824\n",
      "Época: 5, Loss:  2.75071120262146\n",
      "Época: 5, Loss:  1.0392234325408936\n",
      "Época: 5, Loss:  3.5777201652526855\n",
      "Época: 5, Loss:  0.5224456191062927\n",
      "Época: 5, Loss:  0.9886049628257751\n",
      "Época: 5, Loss:  1.6309840679168701\n",
      "Época: 6, Loss:  3.126218557357788\n",
      "Época: 6, Loss:  0.5466132164001465\n",
      "Época: 6, Loss:  2.6754767894744873\n",
      "Época: 6, Loss:  2.559379816055298\n",
      "Época: 6, Loss:  0.4065677225589752\n",
      "Época: 6, Loss:  2.186784267425537\n",
      "Época: 6, Loss:  1.0207539796829224\n",
      "Época: 6, Loss:  2.8158881664276123\n",
      "Época: 6, Loss:  1.6765369176864624\n",
      "Época: 6, Loss:  1.78871488571167\n",
      "Época: 6, Loss:  2.3197238445281982\n",
      "Época: 6, Loss:  2.2924318313598633\n",
      "Época: 6, Loss:  4.083873748779297\n",
      "Época: 6, Loss:  2.1288986206054688\n",
      "Época: 6, Loss:  4.032690048217773\n",
      "Época: 6, Loss:  2.527902841567993\n",
      "Época: 6, Loss:  3.488663673400879\n",
      "Época: 6, Loss:  2.514857769012451\n",
      "Época: 6, Loss:  2.2798962593078613\n",
      "Época: 6, Loss:  1.2511879205703735\n",
      "Época: 6, Loss:  2.692443609237671\n",
      "Época: 6, Loss:  2.305499315261841\n",
      "Época: 7, Loss:  3.0050885677337646\n",
      "Época: 7, Loss:  2.1640658378601074\n",
      "Época: 7, Loss:  1.5105842351913452\n",
      "Época: 7, Loss:  2.29990816116333\n",
      "Época: 7, Loss:  2.3984668254852295\n",
      "Época: 7, Loss:  3.7701780796051025\n",
      "Época: 7, Loss:  1.7840054035186768\n",
      "Época: 7, Loss:  1.5049657821655273\n",
      "Época: 7, Loss:  2.2644004821777344\n",
      "Época: 7, Loss:  3.0299336910247803\n",
      "Época: 7, Loss:  0.5388919711112976\n",
      "Época: 7, Loss:  1.3574159145355225\n",
      "Época: 7, Loss:  2.1627626419067383\n",
      "Época: 7, Loss:  0.40528741478919983\n",
      "Época: 7, Loss:  2.786529779434204\n",
      "Época: 7, Loss:  1.0847772359848022\n",
      "Época: 7, Loss:  2.048905611038208\n",
      "Época: 7, Loss:  3.2889561653137207\n",
      "Época: 7, Loss:  1.6702553033828735\n",
      "Época: 7, Loss:  3.184530735015869\n",
      "Época: 7, Loss:  1.9441814422607422\n",
      "Época: 7, Loss:  3.129469633102417\n",
      "Época: 8, Loss:  1.5169516801834106\n",
      "Época: 8, Loss:  1.6480273008346558\n",
      "Época: 8, Loss:  2.2739789485931396\n",
      "Época: 8, Loss:  2.4568030834198\n",
      "Época: 8, Loss:  1.6454633474349976\n",
      "Época: 8, Loss:  3.399488925933838\n",
      "Época: 8, Loss:  2.6344504356384277\n",
      "Época: 8, Loss:  0.3018897771835327\n",
      "Época: 8, Loss:  1.7482428550720215\n",
      "Época: 8, Loss:  2.730104923248291\n",
      "Época: 8, Loss:  0.3213130831718445\n",
      "Época: 8, Loss:  3.654625654220581\n",
      "Época: 8, Loss:  2.3423233032226562\n",
      "Época: 8, Loss:  0.29735371470451355\n",
      "Época: 8, Loss:  1.4010605812072754\n",
      "Época: 8, Loss:  0.8689610958099365\n",
      "Época: 8, Loss:  1.3290340900421143\n",
      "Época: 8, Loss:  1.2784972190856934\n",
      "Época: 8, Loss:  1.5585204362869263\n",
      "Época: 8, Loss:  0.44291767477989197\n",
      "Época: 8, Loss:  2.4837186336517334\n",
      "Época: 8, Loss:  0.43854501843452454\n",
      "Época: 9, Loss:  1.6349891424179077\n",
      "Época: 9, Loss:  0.3365943133831024\n",
      "Época: 9, Loss:  2.3581151962280273\n",
      "Época: 9, Loss:  1.2278215885162354\n",
      "Época: 9, Loss:  1.0803049802780151\n",
      "Época: 9, Loss:  1.8129674196243286\n",
      "Época: 9, Loss:  1.382426381111145\n",
      "Época: 9, Loss:  0.21408513188362122\n",
      "Época: 9, Loss:  1.8425970077514648\n",
      "Época: 9, Loss:  0.5379042625427246\n",
      "Época: 9, Loss:  2.1583290100097656\n",
      "Época: 9, Loss:  0.655143678188324\n",
      "Época: 9, Loss:  3.2601237297058105\n",
      "Época: 9, Loss:  1.12416410446167\n",
      "Época: 9, Loss:  2.5834996700286865\n",
      "Época: 9, Loss:  0.35738664865493774\n",
      "Época: 9, Loss:  3.444530725479126\n",
      "Época: 9, Loss:  1.6318740844726562\n",
      "Época: 9, Loss:  3.2223331928253174\n",
      "Época: 9, Loss:  4.44221830368042\n",
      "Época: 9, Loss:  1.842253565788269\n",
      "Época: 9, Loss:  2.3754310607910156\n",
      "Época: 10, Loss:  1.5661276578903198\n",
      "Época: 10, Loss:  2.174088954925537\n",
      "Época: 10, Loss:  1.829765796661377\n",
      "Época: 10, Loss:  2.1017568111419678\n",
      "Época: 10, Loss:  2.08925724029541\n",
      "Época: 10, Loss:  2.6875545978546143\n",
      "Época: 10, Loss:  2.2191338539123535\n",
      "Época: 10, Loss:  1.998943567276001\n",
      "Época: 10, Loss:  2.4367635250091553\n",
      "Época: 10, Loss:  2.3482775688171387\n",
      "Época: 10, Loss:  1.2815496921539307\n",
      "Época: 10, Loss:  3.695681571960449\n",
      "Época: 10, Loss:  1.5376051664352417\n",
      "Época: 10, Loss:  3.0725440979003906\n",
      "Época: 10, Loss:  3.091501235961914\n",
      "Época: 10, Loss:  2.39819073677063\n",
      "Época: 10, Loss:  2.4490060806274414\n",
      "Época: 10, Loss:  2.340496063232422\n",
      "Época: 10, Loss:  1.7545534372329712\n",
      "Época: 10, Loss:  1.2676674127578735\n",
      "Época: 10, Loss:  2.2168045043945312\n",
      "Época: 10, Loss:  0.5815199017524719\n",
      "Época: 11, Loss:  0.3424980640411377\n",
      "Época: 11, Loss:  1.1127861738204956\n",
      "Época: 11, Loss:  3.398319721221924\n",
      "Época: 11, Loss:  2.7125296592712402\n",
      "Época: 11, Loss:  1.43198823928833\n",
      "Época: 11, Loss:  1.9860010147094727\n",
      "Época: 11, Loss:  1.6991952657699585\n",
      "Época: 11, Loss:  2.72040057182312\n",
      "Época: 11, Loss:  3.062285900115967\n",
      "Época: 11, Loss:  2.7599644660949707\n",
      "Época: 11, Loss:  2.547614336013794\n",
      "Época: 11, Loss:  2.3643147945404053\n",
      "Época: 11, Loss:  0.48489728569984436\n",
      "Época: 11, Loss:  3.9275693893432617\n",
      "Época: 11, Loss:  1.755329966545105\n",
      "Época: 11, Loss:  1.5069273710250854\n",
      "Época: 11, Loss:  0.3653007447719574\n",
      "Época: 11, Loss:  3.78446888923645\n",
      "Época: 11, Loss:  2.822160005569458\n",
      "Época: 11, Loss:  0.8049916625022888\n",
      "Época: 11, Loss:  3.822788715362549\n",
      "Época: 11, Loss:  1.8161183595657349\n",
      "Época: 12, Loss:  0.22334258258342743\n",
      "Época: 12, Loss:  1.7857049703598022\n",
      "Época: 12, Loss:  1.7907569408416748\n",
      "Época: 12, Loss:  1.939804196357727\n",
      "Época: 12, Loss:  1.9817039966583252\n",
      "Época: 12, Loss:  1.296212077140808\n",
      "Época: 12, Loss:  1.6699156761169434\n",
      "Época: 12, Loss:  0.3193284869194031\n",
      "Época: 12, Loss:  3.186704635620117\n",
      "Época: 12, Loss:  3.5512490272521973\n",
      "Época: 12, Loss:  3.4420628547668457\n",
      "Época: 12, Loss:  1.7248179912567139\n",
      "Época: 12, Loss:  3.8682491779327393\n",
      "Época: 12, Loss:  0.2779763638973236\n",
      "Época: 12, Loss:  0.2305152267217636\n",
      "Época: 12, Loss:  2.6681511402130127\n",
      "Época: 12, Loss:  1.6900804042816162\n",
      "Época: 12, Loss:  1.627825140953064\n",
      "Época: 12, Loss:  2.1423869132995605\n",
      "Época: 12, Loss:  0.4292808473110199\n",
      "Época: 12, Loss:  2.6789844036102295\n",
      "Época: 12, Loss:  0.2998259663581848\n",
      "Época: 13, Loss:  1.5758253335952759\n",
      "Época: 13, Loss:  0.824513852596283\n",
      "Época: 13, Loss:  1.9068257808685303\n",
      "Época: 13, Loss:  2.9645040035247803\n",
      "Época: 13, Loss:  1.278565764427185\n",
      "Época: 13, Loss:  1.6533809900283813\n",
      "Época: 13, Loss:  2.0155160427093506\n",
      "Época: 13, Loss:  2.1623940467834473\n",
      "Época: 13, Loss:  2.2571427822113037\n",
      "Época: 13, Loss:  1.9293200969696045\n",
      "Época: 13, Loss:  2.175142288208008\n",
      "Época: 13, Loss:  2.7860569953918457\n",
      "Época: 13, Loss:  2.7673065662384033\n",
      "Época: 13, Loss:  1.8188196420669556\n",
      "Época: 13, Loss:  0.5774855613708496\n",
      "Época: 13, Loss:  2.272797107696533\n",
      "Época: 13, Loss:  1.9529554843902588\n",
      "Época: 13, Loss:  2.3638834953308105\n",
      "Época: 13, Loss:  2.8577842712402344\n",
      "Época: 13, Loss:  0.5838068723678589\n",
      "Época: 13, Loss:  1.4144457578659058\n",
      "Época: 13, Loss:  3.5523581504821777\n",
      "Época: 14, Loss:  0.21702735126018524\n",
      "Época: 14, Loss:  0.798572301864624\n",
      "Época: 14, Loss:  0.8034215569496155\n",
      "Época: 14, Loss:  1.4526339769363403\n",
      "Época: 14, Loss:  1.264424204826355\n",
      "Época: 14, Loss:  1.5772006511688232\n",
      "Época: 14, Loss:  0.46374547481536865\n",
      "Época: 14, Loss:  1.8972363471984863\n",
      "Época: 14, Loss:  2.8569138050079346\n",
      "Época: 14, Loss:  1.7755876779556274\n",
      "Época: 14, Loss:  1.5260542631149292\n",
      "Época: 14, Loss:  1.7437143325805664\n",
      "Época: 14, Loss:  1.1455408334732056\n",
      "Época: 14, Loss:  1.2486753463745117\n",
      "Época: 14, Loss:  3.1393134593963623\n",
      "Época: 14, Loss:  3.982684373855591\n",
      "Época: 14, Loss:  2.6568949222564697\n",
      "Época: 14, Loss:  2.056678533554077\n",
      "Época: 14, Loss:  3.0781636238098145\n",
      "Época: 14, Loss:  0.22283926606178284\n",
      "Época: 14, Loss:  1.370524287223816\n",
      "Época: 14, Loss:  1.0917636156082153\n",
      "Época: 15, Loss:  2.5835769176483154\n",
      "Época: 15, Loss:  0.2631312906742096\n",
      "Época: 15, Loss:  2.0571255683898926\n",
      "Época: 15, Loss:  2.5849788188934326\n",
      "Época: 15, Loss:  2.60837984085083\n",
      "Época: 15, Loss:  1.7505732774734497\n",
      "Época: 15, Loss:  0.7741307616233826\n",
      "Época: 15, Loss:  1.2089838981628418\n",
      "Época: 15, Loss:  0.9742441177368164\n",
      "Época: 15, Loss:  0.15121836960315704\n",
      "Época: 15, Loss:  1.8047738075256348\n",
      "Época: 15, Loss:  1.0337445735931396\n",
      "Época: 15, Loss:  1.0554735660552979\n",
      "Época: 15, Loss:  3.003065586090088\n",
      "Época: 15, Loss:  1.878397822380066\n",
      "Época: 15, Loss:  0.35173431038856506\n",
      "Época: 15, Loss:  1.8552076816558838\n",
      "Época: 15, Loss:  3.74814510345459\n",
      "Época: 15, Loss:  1.7961887121200562\n",
      "Época: 15, Loss:  1.8521294593811035\n",
      "Época: 15, Loss:  1.5222139358520508\n",
      "Época: 15, Loss:  2.1703248023986816\n",
      "Treinamento concluído!\n",
      "\n",
      "\n",
      "CPU times: user 8h 46min 32s, sys: 26min 57s, total: 9h 13min 30s\n",
      "Wall time: 6h 14min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenizer, model, val_loader = init_training_pipeline(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.TextIOWrapper name='predictions.csv' mode='w+' encoding='UTF-8'>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(\"predictions.csv\",\"w+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(epoch, tokenizer, model, device, loader):\n",
    "    model.eval()\n",
    "    source_texts = []\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(loader, 0):\n",
    "            ids = data['source_ids'].to(device, dtype=torch.long)\n",
    "            y = data['target_ids'].to(device, dtype=torch.long)\n",
    "            mask = data['source_mask'].to(device, dtype=torch.long)\n",
    "\n",
    "            generated_ids = model.generate(\n",
    "                input_ids=ids,\n",
    "                attention_mask=mask,\n",
    "                max_length=350,\n",
    "                num_beams=2,\n",
    "                repetition_penalty=1.5,\n",
    "                length_penalty=1,\n",
    "                early_stopping=True\n",
    "            )\n",
    "            \n",
    "            src_texts = [tokenizer.decode(s, skip_special_tokens=True, clean_up_tokenization_spaces=True) for s in ids]\n",
    "            preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n",
    "            target = [tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True) for t in y]\n",
    "\n",
    "            if _ % 100 == 0 and _ > 0:\n",
    "                print(f'Resumos: {_} gerados')\n",
    "            \n",
    "            source_texts.extend(src_texts)\n",
    "            predictions.extend(preds)\n",
    "            actuals.extend(target)\n",
    "\n",
    "    return source_texts, predictions, actuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validade_and_save_predictions(val_epochs, tokenizer, model, val_loader):\n",
    "    # Saving the dataframe as predictions.csv\n",
    "    print('Gerando sumários utilizando o modelo no dataset de validação...')\n",
    "    for epoch in range(val_epochs):\n",
    "        source_texts, predictions, actuals = validate(epoch, tokenizer, model, device, val_loader)\n",
    "        final_df = pd.DataFrame({ 'inteiro_teor_sumarizado': source_texts, 'ementa_original': actuals, 'resumo_gerado': predictions })\n",
    "        final_df.to_csv('predictions.csv')\n",
    "        print('CSV para análise gerado!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gerando sumários utilizando o modelo no dataset de validação...\n",
      "Resumos: 100 gerados\n",
      "Resumos: 200 gerados\n",
      "Resumos: 300 gerados\n",
      "Resumos: 400 gerados\n",
      "Resumos: 500 gerados\n",
      "Resumos: 600 gerados\n",
      "Resumos: 700 gerados\n",
      "Resumos: 800 gerados\n",
      "Resumos: 900 gerados\n",
      "Resumos: 1000 gerados\n",
      "Resumos: 1100 gerados\n",
      "Resumos: 1200 gerados\n",
      "Resumos: 1300 gerados\n",
      "Resumos: 1400 gerados\n",
      "Resumos: 1500 gerados\n",
      "Resumos: 1600 gerados\n",
      "Resumos: 1700 gerados\n",
      "Resumos: 1800 gerados\n",
      "Resumos: 1900 gerados\n",
      "Resumos: 2000 gerados\n",
      "Resumos: 2100 gerados\n",
      "Resumos: 2200 gerados\n",
      "Resumos: 2300 gerados\n",
      "Resumos: 2400 gerados\n",
      "Resumos: 2500 gerados\n",
      "Resumos: 2600 gerados\n",
      "CSV para análise gerado!\n",
      "CPU times: user 14min 52s, sys: 1min 56s, total: 16min 49s\n",
      "Wall time: 16min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "validade_and_save_predictions(config.VAL_EPOCHS, tokenizer, model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemplo 10 \n",
      "\n",
      "Inteiro teor:  8th class) gmmea / hagb / acnv This document of interlocutory appeal was reviewed, reported and discussed in resource of magazine n ° tst-airr-127740-66.2008.5.02.000, in which joyce de lime is aggravating and silva and silva associate lawyers and professional cooperative of the professionals are aggravated credit and collection - cccoop. 95, which denied following up on its review appeal. remittance of the records to the public labor ministry is waived, according to art. thus renews its denunciation of violation of art. it should be noted that, under the terms of art. 896, § 6, of the clt, in the case of a subject subject to the extremely brief procedure, the appropriateness of the review appeal will only be admitted due to the contradiction of the tst jurisprudence summary or direct affront to the constitution of the republic. as a result, the alleged violation of an infraconstitutional precept does not authorize the processing of the appeal. \n",
      "\n",
      "\n",
      "Ementa original:  interlocutory appeal in review appeal - extremely brief procedure. union framework. art. 896, § 6, of clt. in the cases subject to the summary procedure, only a review appeal will be allowed due to the contrary, the summary of uniform jurisprudence of the superior labor court and direct violation of the constitution of the republic. interlocutory appeal that was dismissed. \n",
      "\n",
      "\n",
      "Sumário gerado:  the interlocutory appeal. \n",
      "\n",
      "\n",
      "Exemplo 11 \n",
      "\n",
      "Inteiro teor:  the c o rd (6th class) gmmgd / ja / jr these visas of declaration embargoes in an interlocutory appeal were reviewed, reported and discussed in resource of magazine n ° tst-ed-airr-82640-60.2001.5.02.002, in which embargo is eletropaulo - metropolitan electricity of são paulo s.a. 6th class, by means of the judgment now suspended, was not aware of the interlocutory appeal filed by the defendant, given the incomplete transfer of the denial decision to follow up on the appeal. 897 of the clt, without which it is impossible to verify the timing of the interlocutory appeal. for the foregoing, I dismiss the motion for clarification. that said, the ministers of the sixth class of the higher labor court agree, unanimously, to dismiss the embargoes of declaration. \n",
      "\n",
      "\n",
      "Ementa original:  declaration embargoes. art. 897-a of clt. no motion for clarification, pursuant to art. 897-a, of the clt, if the ruled embargo is correct when it concludes that the instrument is not aware of the interlocutory appeal, given the non-fulfillment of the extrinsic assumptions of the appeal. declaration embargoes not provided. \n",
      "\n",
      "\n",
      "Sumário gerado:  the interlocutory appeal. declaration embargoes rejected when its own grounds for clarification is dismissed by means of hypotheses provided specified in arts. 535, items i and 897-a of the clt). \n",
      "\n",
      "\n",
      "Exemplo 12 \n",
      "\n",
      "Inteiro teor:  judgment 6th class acv / mgf / b This document of interlocutory appeal was reviewed, reported and discussed in resource of magazine n ° tst-airr-86340-52.2007.5.04.000, in which it is an aggravating foundation of federal economists - funcef and aggravated misedi kupske and federal savings bank - cef. there is no manifestation of the learned public ministry of labor. vote i - I am aware of the interlocutory appeal, since it is regular and timely. ii - merit in view of the decision handed down in cef's review appeal that runs alongside it, and that examined all the matters that are the object of this appeal (prescription, solidarity among the defendants and supplementary retirement), having even dismissed the action in the regarding the supplementation of retirement, the analysis of this appeal is impaired. \n",
      "\n",
      "\n",
      "Ementa original:  interlocutory appeal. prescription, solidarity of the defendants and supplementary retirement. in view of the decision handed down in cef's review appeal, which examined all these matters, having even dismissed the action that claimed differences in supplementing retirement, the analysis of this appeal is impaired. \n",
      "\n",
      "\n",
      "Sumário gerado:  the interlocutory appeal. \n",
      "\n",
      "\n",
      "Exemplo 13 \n",
      "\n",
      "Inteiro teor:  judgment 5th class ka / pg this document of interlocutory appeal was reviewed, reported and discussed in resource of magazine n ° tst-airr-117740-43.2004.5.01.001, which is an aggravating super highway concessionaire for rail transportation s.a. without referral to the public labor ministry (art. irregularity in the formation of the instrument. emphasis added] it should be noted that normative instruction no. this being said, the ministers of the fifth class of the higher labor court agree, unanimously, not to know the bill of instrument. \n",
      "\n",
      "\n",
      "Ementa original:  interlocutory appeal. magazine feature. irregularity in the formation of the instrument. insufficient transfer. lack of essential parts. it is not known of an interlocutory appeal when it does not contain a copy of the pieces essential to its formation, according to item iii of normative instruction nº 16/99 of tst. grievance of an instrument that is not known. \n",
      "\n",
      "\n",
      "Sumário gerado:  the interlocutory appeal. \n",
      "\n",
      "\n",
      "Exemplo 14 \n",
      "\n",
      "Inteiro teor:  the c o rd (3rd class) gmalb / rhs / abn / mn visas, reported and discussed these notices of embargoes of declaration in resource of magazine n ° tst-ed-rr-130740-02.2007.5.02.000, in which neide de morais zuppo and others are embargoes embargo federal savings - cef. 402, dated 10.24.78, of the resolution of the company's board of directors. court expressly expressed itself on the issues listed by the party in a review appeal, dismissing the regional thesis and granting the appeal to grant the aid installment payment - food, restoring the sentence, in particular. in this sense, the plaintiffs' allegation, raised only in the declaratory embargoes, constitutes a reprehensible and unreasonable innovation. thus, there is no evidence of any defect in the embargoed decision. opposed to the drift of the situations referred to in arts. that said, the ministers of the third class of the higher labor court agree, unanimously, to reject the declaratory embargoes. \n",
      "\n",
      "\n",
      "Ementa original:  declaration embargoes. misplacement. opposed to the drift of the situations referred to in arts. 535, items i and ii, of the cpc and 897-a and single paragraph, of the clt, rejected are the embargoes of declaration. \n",
      "\n",
      "\n",
      "Sumário gerado:  the declaration embargoes of an interlocutory appeal. \n",
      "\n",
      "\n",
      "Exemplo 15 \n",
      "\n",
      "Inteiro teor:  judgment 1st class vmf / cm / sc / a visa, report and discussion of these embargoes of declaration embargoes in a resource of magazine n ° tst-ed-rr-89100-47.2003.5.04.002, in which is embarangante rosângela maria pereira and embargadas porto alegre clinics s / c ltda., weingaertner Comércio e Administração Ltda. ( in view of the judgment on pages 642-643, the claimant opposes the present declaration embargos. the hypothesis foreseen in the summary no. the complainant, by way of omission, maintains that the summary no. in fact, despite the aforementioned transfer showing the legal nature of an uncontroversial fact, the court of origin, based on the other evidence in the file, did not consider it sufficient to characterize the succession of employers. \n",
      "\n",
      "\n",
      "Ementa original:  embargoes of declaration in review appeal - omission - nonexistence. if the embargoed judgment does not contemplate any defect among those listed in art. 535, i and ii, of the cpc, the measure brought against him, which undeniably pursues a new trial of the matter, does not warrant approval. declaration embargoes without. \n",
      "\n",
      "\n",
      "Sumário gerado:  the inexistence in v. 535 of the cpc. declaration embargoes not characterized, if any defect to provide clarifications is dismissed. \n",
      "\n",
      "\n",
      "Exemplo 16 \n",
      "\n",
      "Inteiro teor:  the c o rd (6th class) gmmgd / me / jr seen, reported and discussed these records of interlocutory appeal in magazine resource n ° tst-airr-131640-81.2008.5.21.002, in which is aggravating municipality of lagoa de Pedras and aggravated maria josilene de oliveira. nonconformed, the defendant lodges the present interlocutory appeal (pages 2-5). counterclaims and / or counter-reasons were presented, the mpt being officiated by the dismissal of the appeal (pages 79-84). vote i) knowledge that all appeals are met, I know the appeal. useless edge for configuration of praetorian dissent. 896, a, of the clt in the magazine, the defendant protests against the single legal regime theme - publication of the municipal law. to do so, it collects a single tst class edges. in effect, the edge transcribed on pages. for all of the above, I dismiss the interlocutory appeal. \n",
      "\n",
      "\n",
      "Ementa original:  interlocutory appeal. magazine feature. change of legal regime. publication of the municipal law. useless edge for configuration of praetorian dissent. intelligence of art. 896, a, from clt. the edge collected for the configuration of the jurisprudential divergence is useless, since it comes from the tst group. intelligence of art. 896, a, from clt. a record of instrument without. \n",
      "\n",
      "\n",
      "Sumário gerado:  the magazine appeal. interlocutory appeal not known. \n",
      "\n",
      "\n",
      "Exemplo 17 \n",
      "\n",
      "Inteiro teor:  the c o rd (4th class class) gmmac / r3 / fgfl / gn visa, reported and discussed these documents of interlocutory appeal in magazine resource no. tst-airr-129040-60.2005.5.04.002, in which marli oliveira belladona is aggravating and federal savings bank - cef and foundation of federal economists - funcef. r e l a t o r i ndistant with the decision on pages 113-verso / 115, which denied following up on the review appeal, intervenes the plaintiff's interlocutory appeal on pages. 2/20, claiming that the magazine deserved regular processing. remittance of the case to the public labor ministry is waived. That said, the ministers of the fourth class of the higher labor court agree, unanimously, not to be aware of the interlocutory appeal. \n",
      "\n",
      "\n",
      "Ementa original:  interlocutory appeal in magazine appeal. training irregularity. absence of authentication of the transferred parts. the interlocutory appeal does not deserve to be known, when the copies of the parts transferred by the appellant are not authenticated, out of step with the determinations of art. 830 of clt. interlocutory appeal not known. \n",
      "\n",
      "\n",
      "Sumário gerado:  the interlocutory appeal. grievance not known. \n",
      "\n",
      "\n",
      "Exemplo 18 \n",
      "\n",
      "Inteiro teor:  judgment 4th class gmfeo / ds seen, reported and discussed these records of interlocutory appeal in magazine resource n ° tst-airr-84041-27.2006.5.04.000, in which joão carlos araujo fonseca and aggravated vonpar refrescos s.a. the records were not sent to the public labor ministry. irregularity in the formation of the instrument. absence of a copy of the regional judgment in ordinary appeal in art. it appears that the copy of the regional judgment on ordinary appeal is not in the file. it should be noted that, in the normative instruction nº 16 of this court, of 09/13/1999, in its item x, the parties are responsible for ensuring the correct formation of the instrument, establishing the impediment of converting the appeal into diligence, to make up for the absence of parts, albeit essential. this being said, the ministers of the fourth class of the higher labor court agree, unanimously, not to know the interlocutory appeal. \n",
      "\n",
      "\n",
      "Ementa original:  interlocutory appeal. magazine feature. disabled transfer. absence of a copy of the regional judgment. indispensable part for the immediate judgment of the denied appeal. interlocutory appeal instructed in non-compliance with the provisions of art. 897, § 5, i, of clt. grievance of an instrument that is not known. \n",
      "\n",
      "\n",
      "Sumário gerado:  the magazine appeal. interlocutory appeal not known. \n",
      "\n",
      "\n",
      "Exemplo 19 \n",
      "\n",
      "Inteiro teor:  the c o rd (3rd class class) gmalb / mjsr / abn / mki visas, reported and discussed these notices of embargoes of declaration in resource of magazine n ° tst-ed-rr-117400-61.2008.5.04.002, in which go bank Serviços e factoring ltda. and the union of the commercial development companies - factoring of rio grande do sul is suspended. the originals of the declaratory embargoes were only presented on October 1, 2010 (page 169), which shows the failure to observe the term referred to in art. 184 of the cpc regarding the dies a quo, which may coincide with Saturday, Sunday or a public holiday. therefore, when the appeal was submitted via fax on 9/24/2010 (the last day of the deadline), the five-day period for submission of the original started on the following day (9/25/2010), ending on 9/29/2010. compromised assumption of admissibility, I am not aware of the declaration embargoes. \n",
      "\n",
      "\n",
      "Ementa original:  declaration embargoes. timeliness. there are no known embargoes for declaration filed via facsimile, when the originals are filed after the deadline referred to in art. 2nd of law nº 9,800 / 99 (summary nº 387 / tst). declaration embargoes not known. \n",
      "\n",
      "\n",
      "Sumário gerado:  the interlocutory appeal. declaration embargoes rejected when its own grounds for in hypotheses provided for in arts. 535 of the cpc and 897-a of the clt, which undeniably pursues a new trial of the party are not known. \n",
      "\n",
      "\n",
      "Exemplo 20 \n",
      "\n",
      "Inteiro teor:  judgment B.C. 8th class gmmcp / alw / rom these visas of interlocutory appeal were reviewed, reported and discussed in appeal against magazine n ° tst-ag-airr-191240-78.2001.5.02.002, in which telecommunications from são paulo s.a. - telesp is aggravated and aggravated by élvio carlos zanoni. 401, which denied complying with the interlocutory appeal of the defendant. ii - merits the dispatch of pages 401 denied following the interlocutory appeal of the defendant based on articles 896, § 5, of the clt, 557, caput, of the cpc and 5, lxxviii, of the constitution of the republic. in an interlocutory appeal, the defendant alleges that the order that denied the follow-up to the interlocutory appeal lacks justification, which results in a denial of jurisdictional provision. the aggravated order is impossible to reform or reconsider. it should be noted that civil procedural law authorizes the denial of follow-up to an appeal that is manifestly inadmissible, unfounded, impaired or in confrontation with the precedent or precedent of the respective court, the supreme federal court or the superior court (art. 5, lxxviii, of the constitution of the republic. \n",
      "\n",
      "\n",
      "Ementa original:  interlocutory appeal - preliminary nullity for denial of jurisdictional provision the appealed decision was rendered in strict compliance with articles 896, § 5, of the clt, 557, caput, of the cpc and 5, lxxviii, of the constitution, which is why it is impossible to reform or reconsideration. interlocutory appeal dismissed. \n",
      "\n",
      "\n",
      "Sumário gerado:  the interlocutory appeal. grievance not known. \n",
      "\n",
      "\n",
      "Exemplo 21 \n",
      "\n",
      "Inteiro teor:  the c o rd (4th class class) gmmac / r3 / cmf / gri these documents of interlocutory appeal were reviewed, reported and discussed in magazine resource no. counterarguments to the magazine resource, on pages 156/158 and counter-draft to the interlocutory appeal on pages 153/155. it is unnecessary to send the records to the public labor ministry. 2 - merit considering that the defendant's review appeal was granted (runs together - airr-172341-48.2006.5.01.0461) in order to remove the obstacle of defection, to determine the return of the case to the regional court so that it can appreciate the ordinary appeal of the defendant. claimed, as is understood by law, the examination of the present review appeal is impaired. this being said, the ministers of the fourth class of the higher labor court agree unanimously to judge that the interlocutory appeal was harmed. \n",
      "\n",
      "\n",
      "Ementa original:  interlocutory appeal in magazine appeal. considering that the defendant's review appeal was granted in order to, having removed the obstacle of desertion, to determine the return of the case to the regional court for the assessment of the employer's ordinary appeal, as understood by law, the judgment of this interlocutory appeal is impaired. interlocutory appeal. \n",
      "\n",
      "\n",
      "Sumário gerado:  the magazine appeal. interlocutory appeal not known. \n",
      "\n",
      "\n",
      "Exemplo 22 \n",
      "\n",
      "Inteiro teor:  3rd class) gmalb / as / abn / mn these notices of embargoes of declaration were reviewed, reported and discussed in resource of magazine n ° tst-ed-rr-770600-19.2005.5.09.001, in which is embargo hsbc bank brasil sa - multiple bank and other and embargada lisa mara cristoff netipanyj. 62, i, da clt, and as to the fundamentals used. I note that the party seeks, in fact, in an improper way, to re-discuss a decided matter, revealing its non-conformity, and, intending, to all evidence, the reform of the decision that was unfavorable to him, to impose his own view of the case, end which declaration embargoes are not suitable. dissatisfaction with the outcome of the judgment will require other measures, according to the applicable procedural guidelines. thus, there is no evidence of any defect in the embargoed decision. opposed to the drift of the situations referred to in arts. 535, items i and ii, of the cpc and 897-a and single paragraph, of the clt, rejected are the embargoes of declaration. \n",
      "\n",
      "\n",
      "Ementa original:  declaration embargoes. misplacement. interposed to the drift of the situations referred to in arts. 535, items i and ii, of the cpc and 897-a and single paragraph, of the clt, rejected are the embargoes of declaration. \n",
      "\n",
      "\n",
      "Sumário gerado:  the declaration embargoes are rejected. interlocutory appeal when its own grounds for clarification is dismissed by means of hypotheses provided specified in arts. 535, items i and 897-a of clt). \n",
      "\n",
      "\n",
      "Exemplo 23 \n",
      "\n",
      "Inteiro teor:  8th class) gmmea / rh seen, reported and discussed these records of interlocutory appeal in magazine resource n ° tst-airr-5141-96.2003.5.15.001, in which adriano ribeiro and aggravated telecommunications from são paulo s.a. - counterclaims presented by the defendant to pages 144/155. remittance of the records to the public labor ministry is waived, according to art. vote interlocutory appeal in an adhesive magazine resource. 500, iii, of the cpc, the adhesive resource is subordinate to the main resource. thus, maintaining the denial of the follow-up of the defendant's (principal) magazine appeal by this eighth class, implies the necessary inadmissibility of the adhesive magazine appeal, and, therefore, impairs the examination of the interlocutory appeal filed by the claimant, under of art. \n",
      "\n",
      "\n",
      "Ementa original:  interlocutory appeal in an adhesive magazine resource. main resource not admitted. impaired the examination of the interlocutory appeal of the claimant, in view of the lack of the interlocutory appeal of the defendant, filed in the main appeal, under the terms of art. 500, item iii, of the cpc. \n",
      "\n",
      "\n",
      "Sumário gerado:  the adutory appeal. interlocutory appeal not known. \n",
      "\n",
      "\n",
      "Exemplo 24 \n",
      "\n",
      "Inteiro teor:  judgment 6th class acv / cris / s these visas, reports and motions for clarification of motions of appeal were reviewed, in appeal filed by magazine no. the claimant opposes embargoes of declaration (pages 306/309) to the decision handed down on pages 301/304 of the file. points out omission and obscurity as to the analysis of the violations of the provisions of articles 896 and 74 of the clt, as well as in relation to the payment of overtime and reflexes. vote i - knowledge of regularly opposed declaration embargos. this group analyzed the specific admissibility requirements foreseen in article 896 and clt items, maintaining r. order denying the appeal of the magazine, precisely because no literal violation of a constitutional or legal provision has been demonstrated, nor any divergence of jurisprudence suitable for confronting the thesis. therefore, I reject the motion for clarification. \n",
      "\n",
      "\n",
      "Ementa original:  declaration embargoes. omission. hypothesis in which it is not characterized. the inexistence in v. judged to be omission, contradiction or obscurity in the exact terms of article 535 of the code of civil procedure, leads to the rejection of embargoes of declaration. \n",
      "\n",
      "\n",
      "Sumário gerado:  in declaration embargoes of the inexistence. \n",
      "\n",
      "\n",
      "Exemplo 25 \n",
      "\n",
      "Inteiro teor:  judgment 6th class acv / rbb / s seen, reported and discussed these documents of interlocutory appeal in magazine resource n ° tst-airr-222540-70.2009.5.11.001, in which arosuco aromas e juices s. and other olive groves are aggravated. 2/5, claims that the appeal for review is fully applicable. counter-draft presented on pages 187/189. there was no manifestation by the public labor ministry. regional labor court of the 11th region, through the certificate of judgment of fl. 166, dismissed the ordinary appeal filed by the defendant. 818 da clt and brings an edge to the thesis confrontation. it should be noted that the indication of offense to a constitutional provision pointed out only on the grounds of the interlocutory appeal constitutes appeal innovation, a situation that is not permitted in this extraordinary phase. \n",
      "\n",
      "\n",
      "Ementa original:  interlocutory appeal. summary rite. unfounded appeal. deprivation. in the cases subject to the summary procedure, only an appeal for review will be allowed due to the contrary, the summary of uniform jurisprudence of the superior labor court and / or direct violation of the provisions of the federal constitution, in accordance with the provisions of article 896, § 6, of the clt. interlocutory appeal. \n",
      "\n",
      "\n",
      "Sumário gerado:  the interlocutory appeal. \n",
      "\n",
      "\n",
      "Exemplo 26 \n",
      "\n",
      "Inteiro teor:  the c o rd (5th class class) bp / cr visas, reported and discussed these interlocutory appeals in an interlocutory appeal in magazine resource n ° tst-ag-airr-115740-09.2005.5.03.010, in which construtora centro Oeste ltda. - the defendants oppose the appeal to pages 272/301. they maintain that they have lodged the interlocutory appeal on a regular basis, with a full copy of the original action, and that the absence of just one page of the journal resource seems excessive formality, which does not conform to the modern civil process. vote the appeal is timely and is signed by a qualified lawyer. in casu, the copy of the magazine resource was not translated in full, an essential part for its appreciation, and art. it is necessary to add, in due time, the content of item x of the normative instruction 16/99 of this court, which is up to the parties to provide the correct formation of the instrument, not including omission in due diligence to supply the absence of parts, even essential. That said, the ministers of the fifth class of the higher labor court agree, unanimously, to dismiss the appeal. \n",
      "\n",
      "\n",
      "Ementa original:  grievance. transfer disability. the interlocutory appeal was denied due to lack of transfer due to the absence of a full copy of the journal resource. in the grievance, the aggravating factors did not prove the regularity of the transfer. therefore, the appeal is dismissed. interlocutory appeal dismissed. \n",
      "\n",
      "\n",
      "Sumário gerado:  the interlocutory appeal. \n",
      "\n",
      "\n",
      "Exemplo 27 \n",
      "\n",
      "Inteiro teor:  the c o rd (3rd class) gmalb / deao / abn / mki visas, reported and discussed these records of embargoes of declaration in embargoes of declaration in interlocutory appeal in resource of magazine n ° tst-ed-ed-airr-50240-91.2006.5.02.026, in which it is embarrasing to tredegar brasil industry ltda. and embargoed raimundo rodrigues de sousa. there is sufficient reasoning in the main judgment and in the judgment given due to the first embargoes filed, leaving clearly explained the reasons why this group dismissed the nonconformity of the party. the conclusion of the class was the application of oj 125 / sbdi-1 / tst, with no omissions. if the embargo does not agree with the result achieved, it must manage the appropriate resource, and not postpone the solution of the feat, with manifestly delaying incidents. opposed to the drift of the situations referred to in arts. 535, items i and ii, of the cpc and 897-a and single paragraph, of the clt, rejected are the embargoes of declaration. \n",
      "\n",
      "\n",
      "Ementa original:  declaration embargoes. misplacement. interposed to the drift of the situations referred to in arts. 535 of the cpc and 897-a of the clt, rejected are the embargoes of declaration. known and deprived declaration embargoes. \n",
      "\n",
      "\n",
      "Sumário gerado:  the declaration embargoes are rejected. interlocutory appeal when its own grounds for in which denied meets the hypotheses provided specified with articles 535 of the code of civil procedure and 897-a of clt, leads to rule out. declaration that was dismissed. \n",
      "\n",
      "\n",
      "Exemplo 28 \n",
      "\n",
      "Inteiro teor:  the c o rd (8th class) gmdmc / jm / dr / sm these visas of embargoes of declaration in an interlocutory appeal were reviewed, reported and discussed in appeal no. 314/316, on 6/18/2010, arguing the need for pre-questioning. 897-a of the clt and 535 of the cpc, are those that hinder the exercise of the right of the interested party to appeal the decision to the superior instance, which are omission, contradiction or obscurity. in the present case, the authoring union opposes embargoes of declaration, arguing the need to pre-question art. 7, vi and xxix, of the federal constitution. In view of these considerations, it is clear that the present embargoes of declaration do not conform to any of the legal hypotheses for their appropriateness. that said, the ministers of the eighth class of the higher labor court agree, unanimously, to reject the embargoes of declaration. \n",
      "\n",
      "\n",
      "Ementa original:  embargoes of declaration on interlocutory appeal in review appeal. change in the job and salary plan. prescription. single act. none of the defects listed in arts. 897-a of the clt and 535 of the cpc, the present embargoes cannot be accepted. declaration embargoes rejected. \n",
      "\n",
      "\n",
      "Sumário gerado:  the declaration embargoes of an interlocutory appeal. declaration that are rejected when its own grounds for hypotheses provided for in arts. 535, items i and 897-a of clt). \n",
      "\n",
      "\n",
      "Exemplo 29 \n",
      "\n",
      "Inteiro teor:  judgment 6th class acv / tf / s This document of interlocutory appeal was reviewed, reported and discussed in resource of magazine n ° tst-airr-18040-22.2009.5.09.065, in which accentum maintenance and services ltda. and edno de souza santos and the national steel company are aggravated. there was no pronouncement by the public prosecutor in the absence of public interest. vote reasons for not knowing there is no way of knowing the interlocutory appeal. 897 of the clt, in its § 5 provides: § 5. under penalty of not knowing, the parties will promote the formation of the interlocutory appeal in order to enable, if provided, the immediate judgment of the denied appeal, item iii of normative instruction No. in view of the above, I am not aware of the instrument appeal. \n",
      "\n",
      "\n",
      "Ementa original:  interlocutory appeal. absence of parts. disabled transfer. non-knowledge. it is not known of the interlocutory appeal when the parts named in item i of § 5 of art. 897 of the clt, as well as those indispensable for the disentangling of the subject matter at issue. injury not known. \n",
      "\n",
      "\n",
      "Sumário gerado:  the interlocutory appeal. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generated_summaries = pd.read_csv('predictions.csv', encoding='utf-8', error_bad_lines=False, engine=\"python\")\n",
    "for index, row in generated_summaries[10:30].iterrows():\n",
    "    print(f'Exemplo {index}', '\\n')\n",
    "    print('Inteiro teor:', row['inteiro_teor_sumarizado'], '\\n\\n')\n",
    "    print('Ementa original:', row['ementa_original'], '\\n\\n')\n",
    "    print('Sumário gerado:', row['resumo_gerado'], '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.read_csv('predictions.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_scores = []\n",
    "for i in range(len(predictions)):\n",
    "    rouge_score = scorer.score(predictions['ementa_original'][i], predictions['resumo_gerado'][i])\n",
    "    rouge_scores.append(rouge_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_1_f1 = [i['rouge1'][2] for i in rouge_scores]\n",
    "rouge_2_f1 = [i['rouge2'][2] for i in rouge_scores]\n",
    "rouge_L_f1 = [i['rougeL'][2] for i in rouge_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28162419985829795\n",
      "0.13326003384570811\n",
      "0.21854546473544614\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(rouge_1_f1))\n",
    "print(np.mean(rouge_2_f1))\n",
    "print(np.mean(rouge_L_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvando modelo treinado...\n",
      "Modelo salvo na pasta distilbart-sum400-model!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_archive_name = 'distilbart-sum400-model'\n",
    "print('Salvando modelo treinado...')\n",
    "model.save_pretrained(model_archive_name)\n",
    "print(f'Modelo salvo na pasta {model_archive_name}!\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
